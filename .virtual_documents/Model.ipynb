


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline





train_df = pd.read_excel(r"data\Data_Train.xlsx")
train_df.head()


test_df = pd.read_excel(r"data\Test_set.xlsx")
test_df.head()


df = pd.concat([train_df,test_df], ignore_index=True)
df.shape


df.tail()


df.columns





df.info()








df['Date_Journey'] = df['Date_of_Journey'].str.split('/').str[0]
df['Month_Journey'] = df['Date_of_Journey'].str.split('/').str[1]
df['Year_Journey'] = df['Date_of_Journey'].str.split('/').str[2]


df.head()





df['Date_Journey'] = df['Date_Journey'].astype(int)
df['Month_Journey'] = df['Month_Journey'].astype(int)
df['Year_Journey'] = df['Year_Journey'].astype(int)


df.info()





df.drop(columns = 'Date_of_Journey',axis = 1, inplace = True )


df.head(2)





df['Dep_Hour'] = df['Dep_Time'].str.split(':').str[0]
df['Dep_Min'] = df['Dep_Time'].str.split(':').str[1]
df['Dep_Hour'] = df['Dep_Hour'].astype(int)
df['Dep_Min'] = df['Dep_Min'].astype(int)
df.head()


df.drop('Dep_Time',axis=1, inplace = True)


df.head(2)


df.info()








df[df['Duration'].str.split(' ').str[0]=='5m']


df.drop(6474,axis = 0,inplace=True)
df.drop(13343,axis = 0,inplace=True)





df['Duration_hour'] = df['Duration'].str.split(' ').str[0].str.split('h').str[0]
df['Duration_hour'] = df['Duration_hour'].astype(int)
df.head()


df.head()


df['Duration_min'] = df['Duration'].str.split(' ').str[1].str.split('m').str[0]
df.head(3)





df['Duration_min'] = df['Duration_min'].fillna(0)


df['Duration_min'].isnull().sum()


df['Duration_min'] = df['Duration_min'].astype(int)
df.head(3)


df['Total_Duration'] = df['Duration_hour']*60 + df['Duration_min']
df.head()


df.drop(columns = ['Duration_hour','Duration_min','Duration'],axis = 1, inplace = True)


df.head()


df.info()





df['Arrival_Hour'] = df['Arrival_Time'].str.split(' ').str[0].str.split(':').str[0]
df['Arrival_Min'] = df['Arrival_Time'].str.split(' ').str[0].str.split(':').str[1]
df['Arrival_Min'] = df['Arrival_Min'].astype(int)
df['Arrival_Hour'] = df['Arrival_Hour'].astype(int)
df.head()


df.drop(columns = ['Arrival_Time'],axis = 1, inplace = True)


df.info()





df['Total_Stops'].unique()


df['Total_Stops'] = df['Total_Stops'].map({'non-stop' : 0, '2 stops': 2, '1 stop' : 1, '3 stops' : 3, '4 stops' : 4})


df['Total_Stops'].isnull().sum()


df[df['Total_Stops'].isnull()==True]


df.drop(9039,axis = 0, inplace = True)


df.isnull().sum()


df.info()


df.drop(columns = ['Route'],axis = 1, inplace = True)


df.head()


df.describe()








df.head(2)


sns.histplot(data = df , x = 'Price',kde = True, color = 'g')


df['Airline'].value_counts()





sns.histplot(data = df[df['Airline'].isin(df['Airline'].value_counts()[:5].index)] , x = 'Price',kde = True, hue = 'Airline')





df['Source'].value_counts()


sns.histplot(data = df[df['Source'].isin(df['Source'].value_counts()[:3].index)] , x = 'Price',kde = True, hue = 'Source')





df['Destination'].value_counts()


sns.histplot(data = df[df['Destination'].isin(df['Destination'].value_counts().index[:3])] , x = 'Price',kde = True, hue = 'Destination')





sns.histplot(data = df, x = 'Price', hue = 'Total_Stops', kde = True)


sns.histplot(data = df, x = 'Price', kde = True, hue = 'Month_Journey')
plt.show()


sns.countplot(data = df[df['Airline'].isin(df['Airline'].value_counts()[:7].index)] , x = 'Airline')
plt.xticks(rotation = 80)
plt.show()


plt.pie(x = df['Airline'].value_counts()[:5], labels = df['Airline'].value_counts().index[:5], autopct = '%1.2f%%', shadow = True,explode=[0.01,0.1,0.11,0.111,0.1111])
plt.show()


df['Additional_Info'].value_counts()


sns.histplot(data = df[df['Additional_Info'].isin(df['Additional_Info'].value_counts().index[:3])], x = 'Price',  hue = 'Additional_Info')


df.head()


categorical_columns = [column for column in df.columns if df[column].dtype == 'object']
categorical_columns


cont_columns = [column for column in df.columns if df[column].dtype != 'object']
cont_columns


categorical_df = df[categorical_columns]


# from sklearn.preprocessing import OneHotEncoder
# ohe = OneHotEncoder()
# Airline = ohe.fit_transform(categorical_df[['Airline']])


Airline = pd.get_dummies(categorical_df['Airline'], dtype='int', drop_first=True)


Airline


Source = pd.get_dummies(categorical_df['Source'], dtype='int', drop_first=True)


Destination = pd.get_dummies(categorical_df['Destination'], dtype='int', drop_first=True)


Info = pd.get_dummies(categorical_df['Additional_Info'], dtype='int', drop_first=True)


final_df = pd.concat([df[cont_columns], Source, Destination, Info, Airline], axis = 1)


Test_data = final_df[final_df['Price'].isnull() == True ]
Train_data = final_df[final_df['Price'].isnull() != True ]


Test_data.drop('Price', inplace=True, axis = 1)
Test_data


X = Train_data.drop('Price', axis = 1)


y = Train_data['Price']





from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=45)


X_train.shape, X_test.shape





from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor


from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import cross_val_score


CV = []
R2_train = []
R2_test = []
models = []

def pred_model(model,model_name):
    models.append(model_name)
    # Training model
    model.fit(X_train,y_train)
            
    # R2 score of train set
    y_pred_train = model.predict(X_train)
    R2_train_model = r2_score(y_train,y_pred_train)
    R2_train.append(round(R2_train_model,4))
    
    # R2 score of test set
    y_pred_test = model.predict(X_test)
    R2_test_model = r2_score(y_test,y_pred_test)
    R2_test.append(round(R2_test_model,4))
    
    # R2 mean of train set using Cross validation
    cross_val = cross_val_score(model ,X_train ,y_train ,cv=5)
    cv_mean = cross_val.mean()
    CV.append(round(cv_mean,4))
    
    # Printing results
    print("Train R2-score :",round(R2_train_model,4))
    print("Test R2-score :",round(R2_test_model,4))
    print("Train CV scores :",cross_val)
    print("Train CV mean :",round(cv_mean,4))
    
    # Plotting Graphs 
    # Residual Plot of train data
    fig, ax = plt.subplots(1,2,figsize = (10,4))
    ax[0].set_title('Residual Plot of Train samples')
    sns.kdeplot((y_train-y_pred_train),ax = ax[0])
    ax[0].set_xlabel('y_train - y_pred_train')
    
    # Y_test vs Y_train scatter plot
    ax[1].set_title('y_test vs y_pred_test')
    ax[1].scatter(x = y_test, y = y_pred_test)
    ax[1].set_xlabel('y_test')
    ax[1].set_ylabel('y_pred_test')
    
    plt.show()








lr = LinearRegression()
lr.fit(X_train,y_train)


pred_model(lr,"Linear Regression")





# ridge = Ridge()
# pred_model(ridge, "Ridge regression")





# from sklearn.model_selection import RandomizedSearchCV


# params = {
#             "alpha": [0.001, 0.01, 0.05, 0.1, 0.5, 1.0], 
#             "solver" :['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']
#         }

# rd = Ridge()
# rd_rs = RandomizedSearchCV(estimator = rd, param_distributions = params, cv = 5, scoring = 'r2')

# pred_model(rd_rs, "Ridge Hyper")



## After Hyperparameter tuning we get the following hyperparameters 
# rd_rs.best_params_
# {'solver': 'svd', 'alpha': 0.5}


ridge = Ridge(solver='svd', alpha= 0.5)
pred_model(ridge, "Ridge Regression")





# lasso = Lasso()
# pred_model(lasso, "Lasso Regression")
# #train r2 : 0.71
# #test r2 : 0.63





# from sklearn.model_selection import RandomizedSearchCV


# params = {
#     "alpha": [0.001, 0.01, 0.05, 0.1, 0.5, 1.0], 
#     "selection" : ['cyclic','random']
#          }

# ls = Lasso()
# ls_rs = RandomizedSearchCV(estimator = ls, param_distributions = params, cv = 5, scoring = 'r2')

# pred_model(ls_rs, "Lasso Regression")



# After hyperparameter tuning
# ls_rs.best_params_
# # {'selection': 'cyclic', 'alpha': 0.5}


Lasso = Lasso(selection='cyclic', alpha = 0.5)
pred_model(Lasso, "Lasso Regression")





adab = AdaBoostRegressor()
pred_model(adab, "Adaboost Regressor")





# gbr = GradientBoostingRegressor()
# pred_model(gbr, "Gradient Boosting regressor")
# # Train R2-score : 0.8492
# # Test R2-score : 0.7667





# gbr = GradientBoostingRegressor()
# params = {
#         "n_estimators": [50, 100, 150],
#         "learning_rate": [0.01, 0.1, 0.2],
#         "max_depth": [3, 4, 5],
#         "criterion": ['friedman_mse', 'squared_error']
#     }

# gbr_rs = RandomizedSearchCV(estimator=gbr, param_distributions=params, cv = 5, scoring='r2')
# pred_model(gbr_rs, "GradientBoosting Regressor")


## parameters after hyperparameter tuning
# gbr_rs.best_params_
# {'n_estimators': 150,
#  'max_depth': 4,
#  'learning_rate': 0.2,
#  'criterion': 'squared_error'}


gdb = GradientBoostingRegressor(n_estimators=150, max_depth=4,learning_rate= 0.2, criterion='squared_error')
pred_model(gdb, "GradientDescent Regressor")








# rf = RandomForestRegressor()
# pred_model(rf, "Random Forest Regressor")
# # Train R2-score : 0.9853
# # Test R2-score : 0.8449





# rf = RandomForestRegressor()
# params = {
#         'n_estimators': [50, 100, 200, 400, 500, 1000],
#         'max_depth': [None, 10, 20, 30],
#         'min_samples_split': [2, 5, 10, 12, 14],
#         'min_samples_leaf': [1, 2, 4, 6, 8]
#     }

# rf_rs = RandomizedSearchCV(estimator=rf, param_distributions=params, cv =5, scoring='r2')
# pred_model(rf_rs, "RandomForest Regressor")


# rf_rs.best_params_
# {'n_estimators': 500,
#  'min_samples_split': 12,
#  'min_samples_leaf': 2,
#  'max_depth': 30}


rf = RandomForestRegressor(n_estimators=500, min_samples_split=12, min_samples_leaf=2, max_depth=30)
pred_model(rf, "Random Forest")





# dt = DecisionTreeRegressor()
# pred_model(dt, "DecisionTree Regressor")
# # Train R2-score : 0.9962
# # Test R2-score : 0.8008


# dt = DecisionTreeRegressor()

# params = {
#         "max_depth": [None, 10, 20, 30, 40],
#         "min_samples_split": [2, 5, 10, 15, 20],
#         "splitter" : ['best','random'],
        
#      }

# dt_rs = RandomizedSearchCV(estimator=dt, param_distributions=params, cv =5, scoring='r2')
# pred_model(dt_rs, "DecisionTree Regressor")



# dt_rs.best_params_
# {'splitter': 'random', 'min_samples_split': 15, 'max_depth': 30}


dt = DecisionTreeRegressor(splitter='random',min_samples_split=15, max_depth=39)
pred_model(dt, "DecisionTree Regressor")





X_train.columns.duplicated()


models


data = {
    "model" : models,
    "cv" : CV,
    "r2_train" : R2_train,
    "r2_test" : R2_test
}
result = pd.DataFrame(data)
result















